{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I4jQZRs2WUgU"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EIzt_HGyWUgZ",
        "outputId": "524af09a-63c3-49ef-f002-cf335ab93dda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\testproj2\\\\research'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SOA-i-ybWUgb",
        "outputId": "fc082057-7b20-4bad-d366-68563bfca701"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\testproj2'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(\"../\")\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing the 'dataclass' decorator from the 'dataclasses' module  \n",
        "# This helps in creating a simple class to store data without writing boilerplate code  \n",
        "from dataclasses import dataclass  \n",
        "\n",
        "# Importing 'Path' from the 'pathlib' module  \n",
        "# 'Path' is used for handling filesystem paths in an object-oriented way  \n",
        "from pathlib import Path  \n",
        "\n",
        "# Using the '@dataclass' decorator to automatically generate special methods  \n",
        "# like '__init__', '__repr__', and '__eq__' for the class  \n",
        "@dataclass  \n",
        "class DataIngestionConfig:  \n",
        "    # Root directory where all data-related files will be stored  \n",
        "    root_dir: Path  \n",
        "    # URL of the source data that needs to be downloaded  \n",
        "    source_URL: str  \n",
        "    # Local path where the downloaded data file will be stored  \n",
        "    local_data_file: Path  \n",
        "    # Directory where the extracted data will be stored after unzipping  \n",
        "    unzip_dir: Path  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hZlvZVmoWUgc"
      },
      "outputs": [],
      "source": [
        "from src.datascience.constants import *\n",
        "from src.datascience.utils.common import read_yaml, create_directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the ConfigurationManager class to manage configuration settings\n",
        "class ConfigurationManager:  \n",
        "    def __init__(self,  \n",
        "                 config_filepath=CONFIG_FILE_PATH,  # Path to the main configuration file  \n",
        "                 params_filepath=PARAMS_FILE_PATH,  # Path to the parameters file  \n",
        "                 schema_filepath=SCHEMA_FILE_PATH):  # Path to the schema file  \n",
        "        print(config_filepath)\n",
        "\n",
        "        # Reading configuration settings from the YAML files  \n",
        "        self.config = read_yaml(config_filepath)  # Loads the main configuration file  \n",
        "        self.params = read_yaml(params_filepath)  # Loads the parameters file  \n",
        "        self.schema = read_yaml(schema_filepath)  # Loads the schema file  \n",
        "\n",
        "        # Creating necessary directories specified in the configuration  \n",
        "        create_directories([self.config.artifacts_root])  # Ensures the artifact root directory exists  \n",
        "\n",
        "    # Method to get the data ingestion configuration  \n",
        "    def get_data_ingestion_config(self) -> DataIngestionConfig:  \n",
        "        # Extracting data ingestion-related settings from the configuration  \n",
        "        config = self.config.data_ingestion  \n",
        "\n",
        "        # Creating the root directory for data ingestion if it doesn’t exist  \n",
        "        create_directories([config.root_dir])  \n",
        "\n",
        "        # Creating an instance of DataIngestionConfig with necessary parameters  \n",
        "        data_ingestion_config = DataIngestionConfig(  \n",
        "            root_dir=config.root_dir,  # Directory for storing ingested data  \n",
        "            source_URL=config.source_URL,  # URL to fetch the data from  \n",
        "            local_data_file=config.local_data_file,  # Path to store the downloaded data file  \n",
        "            unzip_dir=config.unzip_dir  # Path where extracted files will be stored  \n",
        "        )  \n",
        "\n",
        "        # Returning the configured data ingestion object  \n",
        "        return data_ingestion_config  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s3oE1qd0WUge"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules  \n",
        "import os  # For interacting with the operating system  \n",
        "import zipfile  # For handling ZIP files  \n",
        "import urllib.request as request  # For downloading files from URLs  \n",
        "from src.datascience import logger  # For logging messages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Component - Data Ingestion  \n",
        "\n",
        "# Defining the DataIngestion class for handling data downloading and extraction  \n",
        "class DataIngestion:  \n",
        "    def __init__(self, config: DataIngestionConfig):  \n",
        "        # Initializing with the data ingestion configuration  \n",
        "        self.config = config  \n",
        "\n",
        "    # Method to download the zip file from the source URL  \n",
        "    def download_file(self):  \n",
        "        # Checking if the file already exists in the local directory  \n",
        "        if not os.path.exists(self.config.local_data_file):  \n",
        "            # Downloading the file from the source URL and saving it locally  \n",
        "            filename, headers = request.urlretrieve(  \n",
        "                url=self.config.source_URL,  # URL to fetch the file  \n",
        "                filename=self.config.local_data_file  # Path to save the downloaded file  \n",
        "            )  \n",
        "            # Logging the successful download and header information  \n",
        "            logger.info(f\"{filename} downloaded successfully! Details: \\n{headers}\")  \n",
        "        else:  \n",
        "            # Logging that the file already exists, avoiding redundant downloads  \n",
        "            logger.info(f\"File already exists at {self.config.local_data_file}\")  \n",
        "\n",
        "    # Method to extract the contents of the downloaded ZIP file  \n",
        "    def extract_zip_file(self):  \n",
        "        \"\"\"  \n",
        "        Extracts the ZIP file into the designated data directory.  \n",
        "        \"\"\"  \n",
        "        unzip_path = self.config.unzip_dir  # Path to extract files  \n",
        "        os.makedirs(unzip_path, exist_ok=True)  # Creating the extraction directory if it doesn’t exist  \n",
        "\n",
        "        # Extracting the ZIP file using the zipfile module  \n",
        "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:  \n",
        "            zip_ref.extractall(unzip_path)  # Extracting all contents to the directory  \n",
        "\n",
        "        # Logging the successful extraction  \n",
        "        logger.info(f\"Files extracted successfully to {unzip_path}\")  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IoE4cqLiWUgf",
        "outputId": "5f56f76a-3faf-4af7-db89-82c5e742e661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config\\config.yaml\n",
            "[2025-02-06 22:19:05,975: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
            "[2025-02-06 22:19:05,977: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2025-02-06 22:19:05,980: INFO: common: yaml file: schema.yaml loaded successfully]\n",
            "[2025-02-06 22:19:05,981: INFO: common: created directory at: artifacts]\n",
            "[2025-02-06 22:19:05,982: INFO: common: created directory at: artifacts/data_ingestion]\n",
            "[2025-02-06 22:19:07,189: INFO: 2788082593: artifacts/data_ingestion/data.zip downloaded successfully! Details: \n",
            "Connection: close\n",
            "Content-Length: 23329\n",
            "Cache-Control: max-age=300\n",
            "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
            "Content-Type: application/zip\n",
            "ETag: \"c69888a4ae59bc5a893392785a938ccd4937981c06ba8a9d6a21aa52b4ab5b6e\"\n",
            "Strict-Transport-Security: max-age=31536000\n",
            "X-Content-Type-Options: nosniff\n",
            "X-Frame-Options: deny\n",
            "X-XSS-Protection: 1; mode=block\n",
            "X-GitHub-Request-Id: A056:4DE64:2734A2:369E20:67A4E807\n",
            "Accept-Ranges: bytes\n",
            "Date: Thu, 06 Feb 2025 16:49:12 GMT\n",
            "Via: 1.1 varnish\n",
            "X-Served-By: cache-del21720-DEL\n",
            "X-Cache: MISS\n",
            "X-Cache-Hits: 0\n",
            "X-Timer: S1738860552.286058,VS0,VE335\n",
            "Vary: Authorization,Accept-Encoding,Origin\n",
            "Access-Control-Allow-Origin: *\n",
            "Cross-Origin-Resource-Policy: cross-origin\n",
            "X-Fastly-Request-ID: bfc6eed1db73c939b9002fd25c47e9c452e40690\n",
            "Expires: Thu, 06 Feb 2025 16:54:12 GMT\n",
            "Source-Age: 0\n",
            "\n",
            "]\n",
            "[2025-02-06 22:19:07,194: INFO: 2788082593: Files extracted successfully to artifacts/data_ingestion]\n"
          ]
        }
      ],
      "source": [
        "try:  \n",
        "    # Creating an instance of ConfigurationManager to read configuration files  \n",
        "    config = ConfigurationManager()  \n",
        "    # Retrieving the data ingestion configuration settings  \n",
        "    data_ingestion_config = config.get_data_ingestion_config()  \n",
        "    # Creating an instance of DataIngestion with the retrieved configuration  \n",
        "    data_ingestion = DataIngestion(config=data_ingestion_config)  \n",
        "    # Downloading the data file from the source URL  \n",
        "    data_ingestion.download_file()  \n",
        "    # Extracting the contents of the downloaded ZIP file  \n",
        "    data_ingestion.extract_zip_file()  \n",
        "\n",
        "# Handling any exceptions that may occur during the process  \n",
        "except Exception as e:  \n",
        "    raise e  # Raising the exception to notify about errors  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_75s1e9WUgg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
